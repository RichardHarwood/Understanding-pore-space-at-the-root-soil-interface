# Understanding-pore-space-at-the-root-soil-interface-in-soil
### Overview 
Soil has been referred to as the most complex biomaterial on earth (Young and Crawford 2004), this complexity is increased when the focus is on the plant-soil interface. It is well understood that soil structure and soil biota influence soil health and that plant root architecture and root exudates are influential. The most obvious way that plant roots change soil structure is through physical force. As a plant root navigates through the soil it changes not just the physical structure but also the chemical and biological properties in its immediate vicinity (Hinsinger 2009). During root growth a distinct volume of soil often adheres to the plant root called the rhizosheath, and immediately adjacent to this is an area of soil called the rhizosphere that is distinctly different to bulk soil which is further away from the root system. The rhizosheath and rhizosphere have a very interesting implication: they show that a small volume of soil that is close too, but not touching, the root system can have different structural, chemical, and biological properties to near-by bulk soil. In this distinct volume of soil, bacteria form microaggregates by binding soil particles together with their secretions (Ingham 2009). Examples of root morphology include the presence and size of root hairs, the length of roots along with their branching properties. Examples of rhizosheath properties include the amount of soil adhering to the root and root hairs along the with the proportion of the root covered in soil. Rhizosheath soil can also have a different pore network, different soil aggregate sizes and microbial community. These root and rhizosheath traits change a plants capacity to uptake water and nutrients allowing the plant to tolerate water deficits, heat stress and limited nutrient availability.
<br>

A soils overall productivity is linked, in part, to the size, shape, density and connectiveness of its airspaces. The 3D architecture of a soil influences the rate, flow and retention of water and solutes (Luo et al., 2010). Given the importance of both pores and rhizosheath it is evident that plants need to strike a balance in the amount of soil that covers the root and the porosity of that soil (Schmidt et al. 2012). Root hair length and root hair density would influence this balance. For example, a plant with long and dense root hairs would have an interface with the pores in the rhizosheath (e.g. Duddek et al 2023). Whilst a plant with no root hairs would only have an interface with the soil and pores immediate to the main root.
<br>

Here we highlight how recent advancements in deep learning (Rippner et al. 2022) provide a framework for extracting 3D root-soil data from uCT datasets, all within the Python programming language. Our workflow allows for a quick and easy overview of the root-soil interface, in particular capturing porosity, tortuosity, the number and size of discrete pores, the number of connections between pores along with the proportion of root surface that is in contact with the pore space. Here we show the workflow on 30 plants (totaling ~60 000 individual images) and demonstrate its capacity to quantify the 3D complexity of the root-soil interface.
<br>

Understanding root morphology and soil structure requires a non-invasive imaging technique, the data presented here is from the Australian Synchrotron (Figure 1a). Synchrotrons provide a much higher throughput then commercial u-ct scanners, however the workflow presented here is generic in nature and is suitable for any volume imagine techniques. Image segmentation starts by generating training data, this is the only non-automated step of the workflow. In open-source image analysis software (e.g. “ImageJ) a corresponding label image is generated for a number of Z slices, this is done in both the XY and ZY orientation (Figure 1b, XY orientation show). These images are then used to train a predictive model (here we use a ResNet model, described in detail with fully reproducible examples in Rippner et al ). The trained model can then be used to predict the probability of each pixel of an unseen image aligning with the training data (model output shown in figure 1c: roots (in red) along with the pore network of the rhizosheath (blue)). A subsample of training data is reserved to test the accuracy of the model, that is, compare the model output to an expertly annotated image.
<br>

Once the images are in the form of labels a suite of information can be quantified ranging from relatively simple (e.g. the proportion of soil that is pore space: porosity), to more complex metrics such as: the distance from the root surface to the nearest pore space (figure 1d, hotter colors indicate that a pore is far away from the root surface), the size and connections of discrete pore regions (figure 1e, shown here is the connections between pores, hotter colors indicate that the distance between pores is greater), the 3D tortuosity of the pore space and the proportion of root touching pores (figure 1f, 3D tortuosity is calculated using random walkers, each colour is a walker and each step is recorded, the walk is terminated when the walker hits soil, root or the pot). Together these metrics describe belowground structural complexity and are described in full detail with reporduble examples in thie repositry (images linked here) 

<p align="center">
<img  src="content/geoderma_fig_1.png" width="450" height="600"/> 
</p>

###### Figure 1: A cross section of volume render of the raw ct data (a) a grayscale Z slice and a corresponding mask used to train the deep learning model (b) roots (red) and pore space (blue) from the output of the deep learning model (c) the distance from the surface of the root to the nearest pore space (hotter colours represent a greater distance: d) the connections between pores, hotter colors indicate that the distance between pores is greater (e) the random walker workflow (each colour is a walker and each step is recorded, the walk is terminated when the walker hits soil, root or the pot: f)   

## Workflow
The very first step is to "wrangle" the data. Volume microscopy data comes in many file formats and shapes. Our images came as 3D TIFFS but we needed then as image sequences (a folder of 2D images, that when joined together create a 3D image). This is done with the “Convert_3D_Images_To_Slices.ipynb”. 
